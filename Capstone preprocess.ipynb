{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\python311\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\python311\\lib\\site-packages (from sentence-transformers) (4.42.4)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\python311\\lib\\site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (from sentence-transformers) (1.25.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\python311\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\python311\\lib\\site-packages (from sentence-transformers) (1.11.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\python311\\lib\\site-packages (from sentence-transformers) (0.24.1)\n",
      "Requirement already satisfied: Pillow in c:\\python311\\lib\\site-packages (from sentence-transformers) (9.5.0)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaisy\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python311\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\python311\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python311\\lib\\site-packages (from imbalanced-learn) (1.25.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\python311\\lib\\site-packages (from imbalanced-learn) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\python311\\lib\\site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\python311\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python311\\lib\\site-packages (from imbalanced-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\python311\\lib\\site-packages (1.6.17)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: six>=1.10 in c:\\python311\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\python311\\lib\\site-packages (from kaggle) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil in c:\\python311\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from kaggle) (4.66.1)\n",
      "Requirement already satisfied: python-slugify in c:\\python311\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\python311\\lib\\site-packages (from kaggle) (1.26.16)\n",
      "Requirement already satisfied: bleach in c:\\python311\\lib\\site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in c:\\python311\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\python311\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->kaggle) (3.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaisy\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Define the path to your kaggle.json file\n",
    "kaggle_json_path = r\"C:\\CapStone New\\kaggle (1).json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle.json has been copied to ~/.kaggle/ directory\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Ensure the .kaggle directory exists\n",
    "kaggle_dir = os.path.expanduser('~/.kaggle')\n",
    "os.makedirs(kaggle_dir, exist_ok=True)\n",
    "\n",
    "# Copy the kaggle.json file to the .kaggle directory\n",
    "shutil.copy(kaggle_json_path, os.path.join(kaggle_dir, 'kaggle.json'))\n",
    "\n",
    "\n",
    "print(\"kaggle.json has been copied to ~/.kaggle/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset and download path\n",
    "dataset = 'arshkon/linkedin-job-postings' \n",
    "download_path = r'C:\\CapStone New\\kaggle_datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/arshkon/linkedin-job-postings\n"
     ]
    }
   ],
   "source": [
    "import kaggle \n",
    "# Ensure the download directory exists\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "# Download the dataset\n",
    "kaggle.api.dataset_download_files(dataset, path=download_path, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\CapStone New\\kaggle_datasets\\postings.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_benefits_encoded.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_companies.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_companies_encoded.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_company_industries_encoded.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_company_specialities_encoded.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_employee_counts_encoded.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_industries.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_industries_encoded.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_job_industries_encoded.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_job_skills_encoded.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_postings.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_postings_encoded.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_postings_nlp.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_salaries.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_salaries_encoded.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\preprocessed_skills_encoded.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\companies\\companies.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\companies\\company_industries.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\companies\\company_specialities.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\companies\\employee_counts.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\jobs\\benefits.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\jobs\\job_industries.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\jobs\\job_skills.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\jobs\\salaries.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\mappings\\industries.csv\n",
      "C:\\CapStone New\\kaggle_datasets\\mappings\\skills.csv\n"
     ]
    }
   ],
   "source": [
    "# List files in the download directory to verify the actual file names\n",
    "for root, dirs, files in os.walk(download_path):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to individual CSV files\n",
    "datasets = {\n",
    "    'postings': os.path.join(download_path, 'postings.csv'),\n",
    "    'companies': os.path.join(download_path, 'companies', 'companies.csv'),\n",
    "    'company_industries': os.path.join(download_path, 'companies', 'company_industries.csv'),\n",
    "    'company_specialities': os.path.join(download_path, 'companies', 'company_specialities.csv'),\n",
    "    'employee_counts': os.path.join(download_path, 'companies', 'employee_counts.csv'),\n",
    "    'benefits': os.path.join(download_path, 'jobs', 'benefits.csv'),\n",
    "    'job_industries': os.path.join(download_path, 'jobs', 'job_industries.csv'),\n",
    "    'job_skills': os.path.join(download_path, 'jobs', 'job_skills.csv'),\n",
    "    'salaries': os.path.join(download_path, 'jobs', 'salaries.csv'),\n",
    "    'industries': os.path.join(download_path, 'mappings', 'industries.csv'),\n",
    "    'skills': os.path.join(download_path, 'mappings', 'skills.csv')\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: postings\n",
      "\n",
      "Head:\n",
      "     job_id            company_name  \\\n",
      "0    921716   Corcoran Sawyer Smith   \n",
      "1   1829192                     NaN   \n",
      "2  10998357  The National Exemplar    \n",
      "3  23221523  Abrams Fensterman, LLP   \n",
      "4  35982263                     NaN   \n",
      "\n",
      "                                               title  \\\n",
      "0                              Marketing Coordinator   \n",
      "1                  Mental Health Therapist/Counselor   \n",
      "2                        Assitant Restaurant Manager   \n",
      "3  Senior Elder Law / Trusts and Estates Associat...   \n",
      "4                                 Service Technician   \n",
      "\n",
      "                                         description  max_salary pay_period  \\\n",
      "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
      "1  At Aspen Therapy and Wellness , we are committ...        50.0     HOURLY   \n",
      "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
      "3  Senior Associate Attorney - Elder Law / Trusts...    175000.0     YEARLY   \n",
      "4  Looking for HVAC service tech with experience ...     80000.0     YEARLY   \n",
      "\n",
      "            location  company_id  views  med_salary  ...        expiry  \\\n",
      "0      Princeton, NJ   2774458.0   20.0         NaN  ...  1.715990e+12   \n",
      "1   Fort Collins, CO         NaN    1.0         NaN  ...  1.715450e+12   \n",
      "2     Cincinnati, OH  64896719.0    8.0         NaN  ...  1.715870e+12   \n",
      "3  New Hyde Park, NY    766262.0   16.0         NaN  ...  1.715488e+12   \n",
      "4     Burlington, IA         NaN    3.0         NaN  ...  1.716044e+12   \n",
      "\n",
      "  closed_time  formatted_experience_level  \\\n",
      "0         NaN                         NaN   \n",
      "1         NaN                         NaN   \n",
      "2         NaN                         NaN   \n",
      "3         NaN                         NaN   \n",
      "4         NaN                         NaN   \n",
      "\n",
      "                                         skills_desc   listed_time  \\\n",
      "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
      "1                                                NaN  1.712858e+12   \n",
      "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
      "3  This position requires a baseline understandin...  1.712896e+12   \n",
      "4                                                NaN  1.713452e+12   \n",
      "\n",
      "  posting_domain sponsored  work_type  currency  compensation_type  \n",
      "0            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
      "1            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
      "2            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
      "3            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
      "4            NaN         0  FULL_TIME       USD        BASE_SALARY  \n",
      "\n",
      "[5 rows x 28 columns] \n",
      "\n",
      "Describe:\n",
      "             job_id    max_salary    company_id          views     med_salary  \\\n",
      "count  1.238490e+05  2.979300e+04  1.221320e+05  122160.000000    6280.000000   \n",
      "mean   3.896402e+09  9.193942e+04  1.220401e+07      14.618247   22015.619876   \n",
      "std    8.404355e+07  7.011101e+05  2.554143e+07      85.903598   52255.873846   \n",
      "min    9.217160e+05  1.000000e+00  1.009000e+03       1.000000       0.000000   \n",
      "25%    3.894587e+09  4.828000e+01  1.435200e+04       3.000000      18.940000   \n",
      "50%    3.901998e+09  8.000000e+04  2.269650e+05       4.000000      25.500000   \n",
      "75%    3.904707e+09  1.400000e+05  8.047188e+06       8.000000    2510.500000   \n",
      "max    3.906267e+09  1.200000e+08  1.034730e+08    9975.000000  750000.000000   \n",
      "\n",
      "         min_salary       applies  original_listed_time  remote_allowed  \\\n",
      "count  2.979300e+04  23320.000000          1.238490e+05         15246.0   \n",
      "mean   6.491085e+04     10.591981          1.713152e+12             1.0   \n",
      "std    4.959738e+05     29.047395          4.848209e+08             0.0   \n",
      "min    1.000000e+00      1.000000          1.701811e+12             1.0   \n",
      "25%    3.700000e+01      1.000000          1.712863e+12             1.0   \n",
      "50%    6.000000e+04      3.000000          1.713395e+12             1.0   \n",
      "75%    1.000000e+05      8.000000          1.713478e+12             1.0   \n",
      "max    8.500000e+07    967.000000          1.713573e+12             1.0   \n",
      "\n",
      "             expiry   closed_time   listed_time  sponsored  \n",
      "count  1.238490e+05  1.073000e+03  1.238490e+05   123849.0  \n",
      "mean   1.716213e+12  1.712928e+12  1.713204e+12        0.0  \n",
      "std    2.321394e+09  3.622893e+08  3.989122e+08        0.0  \n",
      "min    1.712903e+12  1.712346e+12  1.711317e+12        0.0  \n",
      "25%    1.715481e+12  1.712670e+12  1.712886e+12        0.0  \n",
      "50%    1.716042e+12  1.712670e+12  1.713408e+12        0.0  \n",
      "75%    1.716088e+12  1.713283e+12  1.713484e+12        0.0  \n",
      "max    1.729125e+12  1.713562e+12  1.713573e+12        0.0   \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123849 entries, 0 to 123848\n",
      "Data columns (total 28 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   job_id                      123849 non-null  int64  \n",
      " 1   company_name                122130 non-null  object \n",
      " 2   title                       123849 non-null  object \n",
      " 3   description                 123842 non-null  object \n",
      " 4   max_salary                  29793 non-null   float64\n",
      " 5   pay_period                  36073 non-null   object \n",
      " 6   location                    123849 non-null  object \n",
      " 7   company_id                  122132 non-null  float64\n",
      " 8   views                       122160 non-null  float64\n",
      " 9   med_salary                  6280 non-null    float64\n",
      " 10  min_salary                  29793 non-null   float64\n",
      " 11  formatted_work_type         123849 non-null  object \n",
      " 12  applies                     23320 non-null   float64\n",
      " 13  original_listed_time        123849 non-null  float64\n",
      " 14  remote_allowed              15246 non-null   float64\n",
      " 15  job_posting_url             123849 non-null  object \n",
      " 16  application_url             87184 non-null   object \n",
      " 17  application_type            123849 non-null  object \n",
      " 18  expiry                      123849 non-null  float64\n",
      " 19  closed_time                 1073 non-null    float64\n",
      " 20  formatted_experience_level  94440 non-null   object \n",
      " 21  skills_desc                 2439 non-null    object \n",
      " 22  listed_time                 123849 non-null  float64\n",
      " 23  posting_domain              83881 non-null   object \n",
      " 24  sponsored                   123849 non-null  int64  \n",
      " 25  work_type                   123849 non-null  object \n",
      " 26  currency                    36073 non-null   object \n",
      " 27  compensation_type           36073 non-null   object \n",
      "dtypes: float64(11), int64(2), object(15)\n",
      "memory usage: 26.5+ MB\n",
      "\n",
      "Shape:\n",
      "(123849, 28) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "Dataset: companies\n",
      "\n",
      "Head:\n",
      "   company_id                        name  \\\n",
      "0        1009                         IBM   \n",
      "1        1016               GE HealthCare   \n",
      "2        1025  Hewlett Packard Enterprise   \n",
      "3        1028                      Oracle   \n",
      "4        1033                   Accenture   \n",
      "\n",
      "                                         description  company_size  state  \\\n",
      "0  At IBM, we do more than work. We create. We cr...           7.0     NY   \n",
      "1  Every day millions of people feel the impact o...           7.0      0   \n",
      "2  Official LinkedIn of Hewlett Packard Enterpris...           7.0  Texas   \n",
      "3  Weâ€™re a cloud technology company that provides...           7.0  Texas   \n",
      "4  Accenture is a leading global professional ser...           7.0      0   \n",
      "\n",
      "  country              city zip_code                                address  \\\n",
      "0      US  Armonk, New York    10504  International Business Machines Corp.   \n",
      "1      US           Chicago        0                                      -   \n",
      "2      US           Houston    77389            1701 E Mossy Oaks Rd Spring   \n",
      "3      US            Austin    78741                        2300 Oracle Way   \n",
      "4      IE          Dublin 2        0                    Grand Canal Harbour   \n",
      "\n",
      "                                                 url  \n",
      "0               https://www.linkedin.com/company/ibm  \n",
      "1      https://www.linkedin.com/company/gehealthcare  \n",
      "2  https://www.linkedin.com/company/hewlett-packa...  \n",
      "3            https://www.linkedin.com/company/oracle  \n",
      "4         https://www.linkedin.com/company/accenture   \n",
      "\n",
      "Describe:\n",
      "         company_id  company_size\n",
      "count  2.447300e+04  21699.000000\n",
      "mean   2.052239e+07      3.349233\n",
      "std    3.165929e+07      1.904503\n",
      "min    1.009000e+03      1.000000\n",
      "25%    1.654040e+05      2.000000\n",
      "50%    2.738154e+06      3.000000\n",
      "75%    2.624142e+07      5.000000\n",
      "max    1.034730e+08      7.000000 \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24473 entries, 0 to 24472\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   company_id    24473 non-null  int64  \n",
      " 1   name          24472 non-null  object \n",
      " 2   description   24176 non-null  object \n",
      " 3   company_size  21699 non-null  float64\n",
      " 4   state         24451 non-null  object \n",
      " 5   country       24473 non-null  object \n",
      " 6   city          24472 non-null  object \n",
      " 7   zip_code      24445 non-null  object \n",
      " 8   address       24451 non-null  object \n",
      " 9   url           24473 non-null  object \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 1.9+ MB\n",
      "\n",
      "Shape:\n",
      "(24473, 10) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "Dataset: company_industries\n",
      "\n",
      "Head:\n",
      "   company_id                        industry\n",
      "0      391906  Book and Periodical Publishing\n",
      "1    22292832                    Construction\n",
      "2       20300                         Banking\n",
      "3     3570660  Book and Periodical Publishing\n",
      "4      878353         Staffing and Recruiting \n",
      "\n",
      "Describe:\n",
      "         company_id\n",
      "count  2.437500e+04\n",
      "mean   2.038566e+07\n",
      "std    3.158083e+07\n",
      "min    1.009000e+03\n",
      "25%    1.652215e+05\n",
      "50%    2.708302e+06\n",
      "75%    2.503948e+07\n",
      "max    1.034730e+08 \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24375 entries, 0 to 24374\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   company_id  24375 non-null  int64 \n",
      " 1   industry    24375 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 381.0+ KB\n",
      "\n",
      "Shape:\n",
      "(24375, 2) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "Dataset: company_specialities\n",
      "\n",
      "Head:\n",
      "   company_id              speciality\n",
      "0    22292832      window replacement\n",
      "1    22292832  patio door replacement\n",
      "2       20300      Commercial Banking\n",
      "3       20300          Retail Banking\n",
      "4       20300                Mortgage \n",
      "\n",
      "Describe:\n",
      "         company_id\n",
      "count  1.693870e+05\n",
      "mean   1.258875e+07\n",
      "std    2.451128e+07\n",
      "min    1.009000e+03\n",
      "25%    1.103290e+05\n",
      "50%    1.346497e+06\n",
      "75%    1.067675e+07\n",
      "max    1.034588e+08 \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169387 entries, 0 to 169386\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   company_id  169387 non-null  int64 \n",
      " 1   speciality  169387 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.6+ MB\n",
      "\n",
      "Shape:\n",
      "(169387, 2) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "Dataset: employee_counts\n",
      "\n",
      "Head:\n",
      "   company_id  employee_count  follower_count  time_recorded\n",
      "0      391906             186           32508     1712346173\n",
      "1    22292832             311            4471     1712346173\n",
      "2       20300            1053            6554     1712346173\n",
      "3     3570660             383           35241     1712346173\n",
      "4      878353              52           26397     1712346173 \n",
      "\n",
      "Describe:\n",
      "         company_id  employee_count  follower_count  time_recorded\n",
      "count  3.578700e+04    35787.000000    3.578700e+04   3.578700e+04\n",
      "mean   1.668254e+07     6715.874256    2.012616e+05   1.713163e+09\n",
      "std    2.924722e+07    29400.984643    1.114733e+06   3.990869e+05\n",
      "min    1.009000e+03        0.000000    0.000000e+00   1.712346e+09\n",
      "25%    6.059650e+04       56.000000    2.738000e+03   1.712861e+09\n",
      "50%    1.339209e+06      418.000000    1.617800e+04   1.713393e+09\n",
      "75%    1.544092e+07     2945.000000    7.412950e+04   1.713472e+09\n",
      "max    1.034730e+08   751125.000000    3.270284e+07   1.713573e+09 \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35787 entries, 0 to 35786\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   company_id      35787 non-null  int64\n",
      " 1   employee_count  35787 non-null  int64\n",
      " 2   follower_count  35787 non-null  int64\n",
      " 3   time_recorded   35787 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 1.1 MB\n",
      "\n",
      "Shape:\n",
      "(35787, 4) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "Dataset: benefits\n",
      "\n",
      "Head:\n",
      "       job_id  inferred                     type\n",
      "0  3887473071         0        Medical insurance\n",
      "1  3887473071         0         Vision insurance\n",
      "2  3887473071         0         Dental insurance\n",
      "3  3887473071         0                   401(k)\n",
      "4  3887473071         0  Student loan assistance \n",
      "\n",
      "Describe:\n",
      "             job_id      inferred\n",
      "count  6.794300e+04  67943.000000\n",
      "mean   3.896220e+09      0.594969\n",
      "std    9.817292e+07      0.490902\n",
      "min    2.322152e+07      0.000000\n",
      "25%    3.898161e+09      0.000000\n",
      "50%    3.902348e+09      1.000000\n",
      "75%    3.904719e+09      1.000000\n",
      "max    3.906267e+09      1.000000 \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67943 entries, 0 to 67942\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   job_id    67943 non-null  int64 \n",
      " 1   inferred  67943 non-null  int64 \n",
      " 2   type      67943 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "\n",
      "Shape:\n",
      "(67943, 3) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "Dataset: job_industries\n",
      "\n",
      "Head:\n",
      "       job_id  industry_id\n",
      "0  3884428798           82\n",
      "1  3887473071           48\n",
      "2  3887465684           41\n",
      "3  3887467939           82\n",
      "4  3887467939           80 \n",
      "\n",
      "Describe:\n",
      "             job_id    industry_id\n",
      "count  1.648080e+05  164808.000000\n",
      "mean   3.897074e+09     196.155284\n",
      "std    7.624930e+07     594.230895\n",
      "min    9.217160e+05       1.000000\n",
      "25%    3.894876e+09      17.000000\n",
      "50%    3.902342e+09      44.000000\n",
      "75%    3.904719e+09      96.000000\n",
      "max    3.906267e+09    3253.000000 \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164808 entries, 0 to 164807\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype\n",
      "---  ------       --------------   -----\n",
      " 0   job_id       164808 non-null  int64\n",
      " 1   industry_id  164808 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 2.5 MB\n",
      "\n",
      "Shape:\n",
      "(164808, 2) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "Dataset: job_skills\n",
      "\n",
      "Head:\n",
      "       job_id skill_abr\n",
      "0  3884428798      MRKT\n",
      "1  3884428798        PR\n",
      "2  3884428798       WRT\n",
      "3  3887473071      SALE\n",
      "4  3887465684       FIN \n",
      "\n",
      "Describe:\n",
      "             job_id\n",
      "count  2.137680e+05\n",
      "mean   3.896849e+09\n",
      "std    7.834902e+07\n",
      "min    9.217160e+05\n",
      "25%    3.894661e+09\n",
      "50%    3.902323e+09\n",
      "75%    3.904715e+09\n",
      "max    3.906267e+09 \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 213768 entries, 0 to 213767\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   job_id     213768 non-null  int64 \n",
      " 1   skill_abr  213768 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.3+ MB\n",
      "\n",
      "Shape:\n",
      "(213768, 2) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "Dataset: salaries\n",
      "\n",
      "Head:\n",
      "   salary_id      job_id  max_salary  med_salary  min_salary pay_period  \\\n",
      "0          1  3884428798         NaN        20.0         NaN     HOURLY   \n",
      "1          2  3887470552        25.0         NaN        23.0     HOURLY   \n",
      "2          3  3884431523    120000.0         NaN    100000.0     YEARLY   \n",
      "3          4  3884911725    200000.0         NaN     10000.0     YEARLY   \n",
      "4          5  3887473220        35.0         NaN        33.0     HOURLY   \n",
      "\n",
      "  currency compensation_type  \n",
      "0      USD       BASE_SALARY  \n",
      "1      USD       BASE_SALARY  \n",
      "2      USD       BASE_SALARY  \n",
      "3      USD       BASE_SALARY  \n",
      "4      USD       BASE_SALARY   \n",
      "\n",
      "Describe:\n",
      "          salary_id        job_id    max_salary     med_salary    min_salary\n",
      "count  40785.000000  4.078500e+04  3.394700e+04    6838.000000  3.394700e+04\n",
      "mean   20393.000000  3.895564e+09  9.620987e+04   21370.298197  6.508541e+04\n",
      "std    11773.759701  9.496672e+07  6.587373e+05   51338.564166  4.650612e+05\n",
      "min        1.000000  9.217160e+05  1.000000e+00       0.000000  1.000000e+00\n",
      "25%    10197.000000  3.894608e+09  5.000000e+01      18.500000  3.900000e+01\n",
      "50%    20393.000000  3.901980e+09  8.500000e+04      25.000000  6.230000e+04\n",
      "75%    30589.000000  3.904576e+09  1.425000e+05    2207.000000  1.000000e+05\n",
      "max    40785.000000  3.906267e+09  1.200000e+08  750000.000000  8.500000e+07 \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40785 entries, 0 to 40784\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   salary_id          40785 non-null  int64  \n",
      " 1   job_id             40785 non-null  int64  \n",
      " 2   max_salary         33947 non-null  float64\n",
      " 3   med_salary         6838 non-null   float64\n",
      " 4   min_salary         33947 non-null  float64\n",
      " 5   pay_period         40785 non-null  object \n",
      " 6   currency           40785 non-null  object \n",
      " 7   compensation_type  40785 non-null  object \n",
      "dtypes: float64(3), int64(2), object(3)\n",
      "memory usage: 2.5+ MB\n",
      "\n",
      "Shape:\n",
      "(40785, 8) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "Dataset: industries\n",
      "\n",
      "Head:\n",
      "   industry_id                         industry_name\n",
      "0            1       Defense and Space Manufacturing\n",
      "1            3       Computer Hardware Manufacturing\n",
      "2            4                  Software Development\n",
      "3            5          Computer Networking Products\n",
      "4            6  Technology, Information and Internet \n",
      "\n",
      "Describe:\n",
      "       industry_id\n",
      "count   422.000000\n",
      "mean   1342.305687\n",
      "std    1212.022551\n",
      "min       1.000000\n",
      "25%     108.250000\n",
      "50%    1161.500000\n",
      "75%    2279.500000\n",
      "max    3253.000000 \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   industry_id    422 non-null    int64 \n",
      " 1   industry_name  388 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.7+ KB\n",
      "\n",
      "Shape:\n",
      "(422, 2) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "Dataset: skills\n",
      "\n",
      "Head:\n",
      "  skill_abr          skill_name\n",
      "0       ART        Art/Creative\n",
      "1      DSGN              Design\n",
      "2      ADVR         Advertising\n",
      "3      PRDM  Product Management\n",
      "4      DIST        Distribution \n",
      "\n",
      "Describe:\n",
      "       skill_abr    skill_name\n",
      "count         35            35\n",
      "unique        35            35\n",
      "top          ART  Art/Creative\n",
      "freq           1             1 \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   skill_abr   35 non-null     object\n",
      " 1   skill_name  35 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 692.0+ bytes\n",
      "\n",
      "Shape:\n",
      "(35, 2) \n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load each CSV file into a pandas DataFrame\n",
    "dataframes = {name: pd.read_csv(path) for name, path in datasets.items()}\n",
    "\n",
    "# Function to print head, describe, info, and shape\n",
    "def print_dataframe_info(df, name):\n",
    "    print(f\"Dataset: {name}\")\n",
    "    print(\"\\nHead:\")\n",
    "    print(df.head(), \"\\n\")\n",
    "    print(\"Describe:\")\n",
    "    print(df.describe(), \"\\n\")\n",
    "    print(\"Info:\")\n",
    "    df.info()\n",
    "    print(\"\\nShape:\")\n",
    "    print(df.shape, \"\\n\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "# Print information for each DataFrame\n",
    "for name, df in dataframes.items():\n",
    "    print_dataframe_info(df, name)\n",
    "    input(\"Press Enter to continue to the next DataFrame...\")  # Pauses between each DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in postings:\n",
      "job_id                             0\n",
      "company_name                    1719\n",
      "title                              0\n",
      "description                        7\n",
      "max_salary                     94056\n",
      "pay_period                     87776\n",
      "location                           0\n",
      "company_id                      1717\n",
      "views                           1689\n",
      "med_salary                    117569\n",
      "min_salary                     94056\n",
      "formatted_work_type                0\n",
      "applies                       100529\n",
      "original_listed_time               0\n",
      "remote_allowed                108603\n",
      "job_posting_url                    0\n",
      "application_url                36665\n",
      "application_type                   0\n",
      "expiry                             0\n",
      "closed_time                   122776\n",
      "formatted_experience_level     29409\n",
      "skills_desc                   121410\n",
      "listed_time                        0\n",
      "posting_domain                 39968\n",
      "sponsored                          0\n",
      "work_type                          0\n",
      "currency                       87776\n",
      "compensation_type              87776\n",
      "dtype: int64\n",
      "================================================================================\n",
      "\n",
      "Missing values in companies:\n",
      "company_id         0\n",
      "name               1\n",
      "description      297\n",
      "company_size    2774\n",
      "state             22\n",
      "country            0\n",
      "city               1\n",
      "zip_code          28\n",
      "address           22\n",
      "url                0\n",
      "dtype: int64\n",
      "================================================================================\n",
      "\n",
      "Missing values in company_industries:\n",
      "company_id    0\n",
      "industry      0\n",
      "dtype: int64\n",
      "================================================================================\n",
      "\n",
      "Missing values in company_specialities:\n",
      "company_id    0\n",
      "speciality    0\n",
      "dtype: int64\n",
      "================================================================================\n",
      "\n",
      "Missing values in employee_counts:\n",
      "company_id        0\n",
      "employee_count    0\n",
      "follower_count    0\n",
      "time_recorded     0\n",
      "dtype: int64\n",
      "================================================================================\n",
      "\n",
      "Missing values in benefits:\n",
      "job_id      0\n",
      "inferred    0\n",
      "type        0\n",
      "dtype: int64\n",
      "================================================================================\n",
      "\n",
      "Missing values in job_industries:\n",
      "job_id         0\n",
      "industry_id    0\n",
      "dtype: int64\n",
      "================================================================================\n",
      "\n",
      "Missing values in job_skills:\n",
      "job_id       0\n",
      "skill_abr    0\n",
      "dtype: int64\n",
      "================================================================================\n",
      "\n",
      "Missing values in salaries:\n",
      "salary_id                0\n",
      "job_id                   0\n",
      "max_salary            6838\n",
      "med_salary           33947\n",
      "min_salary            6838\n",
      "pay_period               0\n",
      "currency                 0\n",
      "compensation_type        0\n",
      "dtype: int64\n",
      "================================================================================\n",
      "\n",
      "Missing values in industries:\n",
      "industry_id       0\n",
      "industry_name    34\n",
      "dtype: int64\n",
      "================================================================================\n",
      "\n",
      "Missing values in skills:\n",
      "skill_abr     0\n",
      "skill_name    0\n",
      "dtype: int64\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to find and print missing values\n",
    "def find_missing_values(dataframes):\n",
    "    for name, df in dataframes.items():\n",
    "        print(f\"Missing values in {name}:\")\n",
    "        print(df.isnull().sum())\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Find and print missing values\n",
    "find_missing_values(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing duplicates for postings\n",
      "Removing duplicates for companies\n",
      "Removing duplicates for company_industries\n",
      "Removing duplicates for company_specialities\n",
      "Removing duplicates for employee_counts\n",
      "Removing duplicates for benefits\n",
      "Removing duplicates for job_industries\n",
      "Removing duplicates for job_skills\n",
      "Removing duplicates for salaries\n",
      "Removing duplicates for industries\n",
      "Removing duplicates for skills\n"
     ]
    }
   ],
   "source": [
    "# Function to remove duplicates\n",
    "def remove_duplicates(dataframes):\n",
    "    for name, df in dataframes.items():\n",
    "        print(f\"Removing duplicates for {name}\")\n",
    "        dataframes[name] = df.drop_duplicates()\n",
    "\n",
    "# Remove duplicates\n",
    "remove_duplicates(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled and dataframes saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Handle missing values in the companies dataset\n",
    "companies = dataframes['companies'].copy()\n",
    "companies = companies.dropna(subset=['name'])\n",
    "companies['description'] = companies['description'].fillna('No description available')\n",
    "companies['company_size'] = companies['company_size'].fillna(companies['company_size'].median())\n",
    "companies['state'] = companies['state'].fillna(companies['state'].mode()[0])\n",
    "companies = companies.dropna(subset=['city'])\n",
    "companies['zip_code'] = companies['zip_code'].fillna('00000')\n",
    "companies['address'] = companies['address'].fillna('No address available')\n",
    "\n",
    "# Handle missing values in the salaries dataset\n",
    "salaries = dataframes['salaries'].copy()\n",
    "salaries['max_salary'] = salaries['max_salary'].fillna(salaries['max_salary'].median())\n",
    "salaries['med_salary'] = salaries['med_salary'].fillna(salaries['med_salary'].median())\n",
    "salaries['min_salary'] = salaries['min_salary'].fillna(salaries['min_salary'].median())\n",
    "\n",
    "# Handle missing values in the postings dataset\n",
    "postings = dataframes['postings'].copy()\n",
    "postings = postings.dropna(subset=['company_name'])\n",
    "postings['description'] = postings['description'].fillna('No description available')\n",
    "postings['max_salary'] = postings['max_salary'].fillna(postings['max_salary'].median())\n",
    "postings['med_salary'] = postings['med_salary'].fillna(postings['med_salary'].median())\n",
    "postings['min_salary'] = postings['min_salary'].fillna(postings['min_salary'].median())\n",
    "postings['pay_period'] = postings['pay_period'].fillna(postings['pay_period'].mode()[0])\n",
    "postings = postings.dropna(subset=['company_id'])\n",
    "postings['views'] = postings['views'].fillna(postings['views'].median())\n",
    "postings['applies'] = postings['applies'].fillna(postings['applies'].median())\n",
    "postings['remote_allowed'] = postings['remote_allowed'].fillna(postings['remote_allowed'].mode()[0])\n",
    "postings['application_url'] = postings['application_url'].fillna('No application URL')\n",
    "postings['formatted_experience_level'] = postings['formatted_experience_level'].fillna(postings['formatted_experience_level'].mode()[0])\n",
    "postings['skills_desc'] = postings['skills_desc'].fillna('No skills listed')\n",
    "postings['posting_domain'] = postings['posting_domain'].fillna('No domain')\n",
    "postings['currency'] = postings['currency'].fillna(postings['currency'].mode()[0])\n",
    "postings['compensation_type'] = postings['compensation_type'].fillna(postings['compensation_type'].mode()[0])\n",
    "\n",
    "# Handle missing values in the industries dataset\n",
    "industries = dataframes['industries'].copy()\n",
    "industries['industry_name'] = industries['industry_name'].fillna('Unknown Industry')\n",
    "\n",
    "# Save the preprocessed dataframes if needed\n",
    "companies.to_csv(os.path.join(download_path, 'preprocessed_companies.csv'), index=False)\n",
    "salaries.to_csv(os.path.join(download_path, 'preprocessed_salaries.csv'), index=False)\n",
    "postings.to_csv(os.path.join(download_path, 'preprocessed_postings.csv'), index=False)\n",
    "industries.to_csv(os.path.join(download_path, 'preprocessed_industries.csv'), index=False)\n",
    "\n",
    "# Update the dataframes dictionary with the preprocessed data\n",
    "dataframes['companies'] = companies\n",
    "dataframes['salaries'] = salaries\n",
    "dataframes['postings'] = postings\n",
    "dataframes['industries'] = industries\n",
    "\n",
    "print(\"Missing values handled and dataframes saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of postings dataset:\n",
      "      job_id               company_name  \\\n",
      "0     921716      Corcoran Sawyer Smith   \n",
      "2   10998357     The National Exemplar    \n",
      "3   23221523     Abrams Fensterman, LLP   \n",
      "5   91700727  Downtown Raleigh Alliance   \n",
      "6  103254301                 Raw Cereal   \n",
      "\n",
      "                                               title  \\\n",
      "0                              Marketing Coordinator   \n",
      "2                        Assitant Restaurant Manager   \n",
      "3  Senior Elder Law / Trusts and Estates Associat...   \n",
      "5           Economic Development and Planning Intern   \n",
      "6                                           Producer   \n",
      "\n",
      "                                         description  max_salary pay_period  \\\n",
      "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
      "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
      "3  Senior Associate Attorney - Elder Law / Trusts...    175000.0     YEARLY   \n",
      "5  Job summary:The Economic Development & Plannin...        20.0     HOURLY   \n",
      "6  Company DescriptionRaw Cereal is a creative de...    300000.0     YEARLY   \n",
      "\n",
      "            location  company_id  views  med_salary  ...        expiry  \\\n",
      "0      Princeton, NJ   2774458.0   20.0       25.37  ...  1.715990e+12   \n",
      "2     Cincinnati, OH  64896719.0    8.0       25.37  ...  1.715870e+12   \n",
      "3  New Hyde Park, NY    766262.0   16.0       25.37  ...  1.715488e+12   \n",
      "5        Raleigh, NC   1481176.0    9.0       25.37  ...  1.716048e+12   \n",
      "6      United States  81942316.0    7.0       25.37  ...  1.715453e+12   \n",
      "\n",
      "  closed_time  formatted_experience_level  \\\n",
      "0         NaN            Mid-Senior level   \n",
      "2         NaN            Mid-Senior level   \n",
      "3         NaN            Mid-Senior level   \n",
      "5         NaN            Mid-Senior level   \n",
      "6         NaN            Mid-Senior level   \n",
      "\n",
      "                                         skills_desc   listed_time  \\\n",
      "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
      "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
      "3  This position requires a baseline understandin...  1.712896e+12   \n",
      "5                                   No skills listed  1.713456e+12   \n",
      "6                                   No skills listed  1.712861e+12   \n",
      "\n",
      "  posting_domain sponsored   work_type  currency  compensation_type  \n",
      "0      No domain         0   FULL_TIME       USD        BASE_SALARY  \n",
      "2      No domain         0   FULL_TIME       USD        BASE_SALARY  \n",
      "3      No domain         0   FULL_TIME       USD        BASE_SALARY  \n",
      "5      No domain         0  INTERNSHIP       USD        BASE_SALARY  \n",
      "6      No domain         0    CONTRACT       USD        BASE_SALARY  \n",
      "\n",
      "[5 rows x 28 columns] \n",
      "\n",
      "Head of companies dataset:\n",
      "   company_id                        name  \\\n",
      "0        1009                         IBM   \n",
      "1        1016               GE HealthCare   \n",
      "2        1025  Hewlett Packard Enterprise   \n",
      "3        1028                      Oracle   \n",
      "4        1033                   Accenture   \n",
      "\n",
      "                                         description  company_size  state  \\\n",
      "0  At IBM, we do more than work. We create. We cr...           7.0     NY   \n",
      "1  Every day millions of people feel the impact o...           7.0      0   \n",
      "2  Official LinkedIn of Hewlett Packard Enterpris...           7.0  Texas   \n",
      "3  Weâ€™re a cloud technology company that provides...           7.0  Texas   \n",
      "4  Accenture is a leading global professional ser...           7.0      0   \n",
      "\n",
      "  country              city zip_code                                address  \\\n",
      "0      US  Armonk, New York    10504  International Business Machines Corp.   \n",
      "1      US           Chicago        0                                      -   \n",
      "2      US           Houston    77389            1701 E Mossy Oaks Rd Spring   \n",
      "3      US            Austin    78741                        2300 Oracle Way   \n",
      "4      IE          Dublin 2        0                    Grand Canal Harbour   \n",
      "\n",
      "                                                 url  \n",
      "0               https://www.linkedin.com/company/ibm  \n",
      "1      https://www.linkedin.com/company/gehealthcare  \n",
      "2  https://www.linkedin.com/company/hewlett-packa...  \n",
      "3            https://www.linkedin.com/company/oracle  \n",
      "4         https://www.linkedin.com/company/accenture   \n",
      "\n",
      "Head of company_industries dataset:\n",
      "   company_id                        industry\n",
      "0      391906  Book and Periodical Publishing\n",
      "1    22292832                    Construction\n",
      "2       20300                         Banking\n",
      "3     3570660  Book and Periodical Publishing\n",
      "4      878353         Staffing and Recruiting \n",
      "\n",
      "Head of company_specialities dataset:\n",
      "   company_id              speciality\n",
      "0    22292832      window replacement\n",
      "1    22292832  patio door replacement\n",
      "2       20300      Commercial Banking\n",
      "3       20300          Retail Banking\n",
      "4       20300                Mortgage \n",
      "\n",
      "Head of employee_counts dataset:\n",
      "   company_id  employee_count  follower_count  time_recorded\n",
      "0      391906             186           32508     1712346173\n",
      "1    22292832             311            4471     1712346173\n",
      "2       20300            1053            6554     1712346173\n",
      "3     3570660             383           35241     1712346173\n",
      "4      878353              52           26397     1712346173 \n",
      "\n",
      "Head of benefits dataset:\n",
      "       job_id  inferred                     type\n",
      "0  3887473071         0        Medical insurance\n",
      "1  3887473071         0         Vision insurance\n",
      "2  3887473071         0         Dental insurance\n",
      "3  3887473071         0                   401(k)\n",
      "4  3887473071         0  Student loan assistance \n",
      "\n",
      "Head of job_industries dataset:\n",
      "       job_id  industry_id\n",
      "0  3884428798           82\n",
      "1  3887473071           48\n",
      "2  3887465684           41\n",
      "3  3887467939           82\n",
      "4  3887467939           80 \n",
      "\n",
      "Head of job_skills dataset:\n",
      "       job_id skill_abr\n",
      "0  3884428798      MRKT\n",
      "1  3884428798        PR\n",
      "2  3884428798       WRT\n",
      "3  3887473071      SALE\n",
      "4  3887465684       FIN \n",
      "\n",
      "Head of salaries dataset:\n",
      "   salary_id      job_id  max_salary  med_salary  min_salary pay_period  \\\n",
      "0          1  3884428798     85000.0        20.0     62300.0     HOURLY   \n",
      "1          2  3887470552        25.0        25.0        23.0     HOURLY   \n",
      "2          3  3884431523    120000.0        25.0    100000.0     YEARLY   \n",
      "3          4  3884911725    200000.0        25.0     10000.0     YEARLY   \n",
      "4          5  3887473220        35.0        25.0        33.0     HOURLY   \n",
      "\n",
      "  currency compensation_type  \n",
      "0      USD       BASE_SALARY  \n",
      "1      USD       BASE_SALARY  \n",
      "2      USD       BASE_SALARY  \n",
      "3      USD       BASE_SALARY  \n",
      "4      USD       BASE_SALARY   \n",
      "\n",
      "Head of industries dataset:\n",
      "   industry_id                         industry_name\n",
      "0            1       Defense and Space Manufacturing\n",
      "1            3       Computer Hardware Manufacturing\n",
      "2            4                  Software Development\n",
      "3            5          Computer Networking Products\n",
      "4            6  Technology, Information and Internet \n",
      "\n",
      "Head of skills dataset:\n",
      "  skill_abr          skill_name\n",
      "0       ART        Art/Creative\n",
      "1      DSGN              Design\n",
      "2      ADVR         Advertising\n",
      "3      PRDM  Product Management\n",
      "4      DIST        Distribution \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print head of each preprocessed dataframe\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"Head of {name} dataset:\")\n",
    "    print(df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jaisy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jaisy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jaisy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description  \\\n",
      "0  job descriptiona leading real estate firm new ...   \n",
      "2  national exemplar accepting application assist...   \n",
      "3  senior associate attorney elder law trust esta...   \n",
      "5  job summarythe economic development planning i...   \n",
      "6  company descriptionraw cereal creative design ...   \n",
      "\n",
      "                                         skills_desc  \n",
      "0  requirement seeking college graduate student a...  \n",
      "2  currently accepting resume foh asisstant resta...  \n",
      "3  position requires baseline understanding onlin...  \n",
      "5                                       skill listed  \n",
      "6                                       skill listed  \n",
      "0    ibm work create create technologist developer ...\n",
      "1    every day million people feel impact intellige...\n",
      "2    official linkedin hewlett packard enterprise g...\n",
      "3    â€™ cloud technology company provides organizati...\n",
      "4    accenture leading global professional service ...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define the preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Removing punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenizing\n",
    "    words = word_tokenize(text)\n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Join words back into a single string\n",
    "    preprocessed_text = ' '.join(words)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply the preprocessing function to the description columns\n",
    "postings['description'] = postings['description'].apply(preprocess_text)\n",
    "postings['skills_desc'] = postings['skills_desc'].apply(preprocess_text)\n",
    "companies['description'] = companies['description'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows to verify the preprocessing\n",
    "print(postings[['description', 'skills_desc']].head())\n",
    "print(companies['description'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge company-related datasets\n",
    "company_data = dataframes['companies'].merge(dataframes['company_industries'], on='company_id', how='left')\n",
    "company_data = company_data.merge(dataframes['company_specialities'], on='company_id', how='left')\n",
    "company_data = company_data.merge(dataframes['employee_counts'], on='company_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge job-related datasets\n",
    "job_data = dataframes['postings'].merge(dataframes['job_industries'], on='job_id', how='left')\n",
    "job_data = job_data.merge(dataframes['job_skills'], on='job_id', how='left')\n",
    "job_data = job_data.merge(dataframes['salaries'], on='job_id', how='left')\n",
    "job_data = job_data.merge(dataframes['benefits'], on='job_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine postings with company and job data\n",
    "final_data = job_data.merge(company_data, on='company_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Function to encode categorical variables\n",
    "def encode_categorical_variables(df):\n",
    "    # Select categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    # Apply One-Hot Encoding to columns with low cardinality\n",
    "    low_cardinality_cols = [col for col in categorical_cols if df[col].nunique() < 100]\n",
    "    high_cardinality_cols = [col for col in categorical_cols if df[col].nunique() >= 100]\n",
    "    \n",
    "    df_low_card = pd.get_dummies(df[low_cardinality_cols], drop_first=True)\n",
    "    \n",
    "    # Apply Label Encoding to columns with high cardinality\n",
    "    label_encoders = {}\n",
    "    for col in high_cardinality_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # Drop the original low cardinality columns and concatenate the encoded columns\n",
    "    df = df.drop(columns=low_cardinality_cols)\n",
    "    df = pd.concat([df, df_low_card], axis=1)\n",
    "    \n",
    "    return df, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      job_id  company_name  title  description  max_salary  location  \\\n",
      "0     921716          5381  35491        47135        20.0      6228   \n",
      "2   10998357         21335   4945        65212     65000.0      1390   \n",
      "3   23221523           557  57093        89627    175000.0      5332   \n",
      "5   91700727          6440  19531        51524        20.0      6288   \n",
      "6  103254301         17409  45415        16132    300000.0      7678   \n",
      "\n",
      "   company_id  views  med_salary  min_salary  ...  work_type_FULL_TIME  \\\n",
      "0   2774458.0   20.0       25.37        17.0  ...                 True   \n",
      "2  64896719.0    8.0       25.37     45000.0  ...                 True   \n",
      "3    766262.0   16.0       25.37    140000.0  ...                 True   \n",
      "5   1481176.0    9.0       25.37        14.0  ...                False   \n",
      "6  81942316.0    7.0       25.37     60000.0  ...                False   \n",
      "\n",
      "   work_type_INTERNSHIP  work_type_OTHER  work_type_PART_TIME  \\\n",
      "0                 False            False                False   \n",
      "2                 False            False                False   \n",
      "3                 False            False                False   \n",
      "5                  True            False                False   \n",
      "6                 False            False                False   \n",
      "\n",
      "   work_type_TEMPORARY  work_type_VOLUNTEER  currency_CAD  currency_EUR  \\\n",
      "0                False                False         False         False   \n",
      "2                False                False         False         False   \n",
      "3                False                False         False         False   \n",
      "5                False                False         False         False   \n",
      "6                False                False         False         False   \n",
      "\n",
      "   currency_GBP  currency_USD  \n",
      "0         False          True  \n",
      "2         False          True  \n",
      "3         False          True  \n",
      "5         False          True  \n",
      "6         False          True  \n",
      "\n",
      "[5 rows x 49 columns]\n",
      "   company_id   name  description  company_size  state  city  zip_code  \\\n",
      "0        1009  10356        10844           7.0    422   162       884   \n",
      "1        1016   8466         7196           7.0      9   690        29   \n",
      "2        1025   9884        15514           7.0    621  1607      5375   \n",
      "3        1028  15432        23901           7.0    621   203      5525   \n",
      "4        1033    585          656           7.0      9   989        29   \n",
      "\n",
      "   address    url  country_AE  ...  country_SG  country_SV  country_TR  \\\n",
      "0    18253  10359       False  ...       False       False       False   \n",
      "1       48   8530       False  ...       False       False       False   \n",
      "2     4883   9784       False  ...       False       False       False   \n",
      "3     7354  15476       False  ...       False       False       False   \n",
      "4    18147    270       False  ...       False       False       False   \n",
      "\n",
      "   country_TW  country_TZ  country_UA  country_US  country_VE  country_VN  \\\n",
      "0       False       False       False        True       False       False   \n",
      "1       False       False       False        True       False       False   \n",
      "2       False       False       False        True       False       False   \n",
      "3       False       False       False        True       False       False   \n",
      "4       False       False       False       False       False       False   \n",
      "\n",
      "   country_ZA  \n",
      "0       False  \n",
      "1       False  \n",
      "2       False  \n",
      "3       False  \n",
      "4       False  \n",
      "\n",
      "[5 rows x 89 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply encoding to the postings DataFrame\n",
    "postings_encoded, postings_label_encoders = encode_categorical_variables(postings)\n",
    "\n",
    "# Apply encoding to the company DataFrame\n",
    "company_data_encoded, company_label_encoders = encode_categorical_variables(companies)\n",
    "\n",
    "\n",
    "\n",
    "# Verify encoding\n",
    "print(postings_encoded.head())\n",
    "print(company_data_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to C:\\CapStone New\\kaggle_datasets\\cleaned_final_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path where you want to save the cleaned dataset\n",
    "output_path = os.path.join(download_path, 'cleaned_final_data.csv')\n",
    "\n",
    "# Save the final dataset to a CSV file\n",
    "final_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
